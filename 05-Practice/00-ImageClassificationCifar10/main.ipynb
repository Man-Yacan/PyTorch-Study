{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:35:05.130746300Z",
     "start_time": "2023-06-28T04:34:59.936996700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torch.nn import Conv2d, BatchNorm2d, ReLU, Sequential, MaxPool2d, Linear, Flatten, functional, CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 解压图片文件"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "{'airplane': 0,\n 'automobile': 1,\n 'bird': 2,\n 'cat': 3,\n 'deer': 4,\n 'dog': 5,\n 'frog': 6,\n 'horse': 7,\n 'ship': 8,\n 'truck': 9}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODE = 'test'\n",
    "SAVE_PATH = f'./data/cifar-10-python/cifar-10-batches-py/{MODE}/'\n",
    "LABEL_NAME = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "label_dict = {}\n",
    "for i, name in enumerate(LABEL_NAME):\n",
    "    label_dict[name] = i\n",
    "\n",
    "label_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:35:05.143249Z",
     "start_time": "2023-06-28T04:35:05.136747200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data_dict = pickle.load(fo, encoding='bytes')\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:35:05.147653Z",
     "start_time": "2023-06-28T04:35:05.140223900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['./data/cifar-10-python/cifar-10-batches-py\\\\test_batch']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "data_list = glob.glob(f'./data/cifar-10-python/cifar-10-batches-py/{MODE}_batch*')\n",
    "data_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:35:05.152163600Z",
     "start_time": "2023-06-28T04:35:05.144248700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 循环读取文件，保存为图片格式\n",
    "for path in data_list:\n",
    "    data_dict = unpickle(path)\n",
    "    # print(data_dict.keys())\n",
    "    # print(data_dict[b'data'])\n",
    "    # batch_label：批次号；labels：对应标签名称；data：图像数据（3×32×32）；filenames：文件名称\n",
    "\n",
    "    for img_id, img_data in enumerate(data_dict[b'data']):\n",
    "        img_name = data_dict[b'filenames'][img_id]\n",
    "        img_label = LABEL_NAME[int(data_dict[b'labels'][img_id])]\n",
    "        # print(img_name, img_label)\n",
    "\n",
    "        img_data = np.reshape(img_data, [3, 32, -1])  # 图片数据格式为3×32×32\n",
    "        img_data = np.transpose(img_data, (1, 2, 0))  # 将图片格式转换为32×32×3，为什么要这样？我也不理解，但是问题不大，可能是因为cv2的格式、要求\n",
    "        # cv2.imshow('img_data', cv2.resize(img_data, (200, 200)))\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "        # 对训练集图片按照不同标签对应不同的文件夹分类\n",
    "        cur_path = SAVE_PATH + img_label\n",
    "        if not os.path.exists(cur_path):\n",
    "            os.makedirs(cur_path)\n",
    "\n",
    "        # Saving image\n",
    "        cv2.imwrite(cur_path + '/' + img_name.decode('utf-8'), img_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:35:09.462843700Z",
     "start_time": "2023-06-28T04:35:05.153164800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义数据集类并加载数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 训练数据集增强\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.RandomCrop(28),  # 改变大小\n",
    "    transforms.RandomHorizontalFlip(),  # 水平翻转\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transformer = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # 改变大小\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "# 定义读取数据集类\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, img_list, transform=None, loader=None):\n",
    "        super(MyDataset, self).__init__()\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.loader = loader\n",
    "        if not self.loader:\n",
    "            self.loader = self.image_loader\n",
    "\n",
    "        self.img_info = []\n",
    "        for path in img_list:\n",
    "            img_label = path.split('\\\\')[-2]\n",
    "            self.img_info.append((path, LABEL_NAME.index(img_label)))\n",
    "            # img_info.append((path, label_dict[img_label]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, img_label = self.img_info[index]\n",
    "\n",
    "        img_data = self.loader(img_path)\n",
    "        # 是否进行图像增强处理\n",
    "        if self.transform:\n",
    "            img_data = self.transform(img_data)\n",
    "        return img_data, img_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_info)\n",
    "\n",
    "    @staticmethod\n",
    "    def image_loader(path):\n",
    "        return Image.open(path).convert('RGB')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:35:09.469884Z",
     "start_time": "2023-06-28T04:35:09.466843700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(50000, 10000)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取全部的训练集图片路径以及测试集图片路径\n",
    "img_train_list = glob.glob('./data/cifar-10-python/cifar-10-batches-py/train/*/*.png')\n",
    "img_test_list = glob.glob('./data/cifar-10-python/cifar-10-batches-py/test/*/*.png')\n",
    "\n",
    "train_dataset = MyDataset(img_train_list, transform=train_transformer)  # 测试集图片需要进行图片增强处理\n",
    "test_dataset = MyDataset(img_test_list, transform=transforms.ToTensor())  # 训练集图片不需要\n",
    "len(train_dataset), len(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:35:09.847025100Z",
     "start_time": "2023-06-28T04:35:09.470884200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 加载数据集类"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(8334, 1667)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=6,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=6,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "len(train_loader), len(test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:35:09.853356600Z",
     "start_time": "2023-06-28T04:35:09.842688400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(50000, 10000)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset), len(test_loader.dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:35:09.854357600Z",
     "start_time": "2023-06-28T04:35:09.849035500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 搭建VGGNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class VGGNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGNet, self).__init__()\n",
    "\n",
    "        self.model = Sequential(\n",
    "            # 00\n",
    "            Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(64),  # num_features：一般输入参数为batch_size*num_features*height*width，即为其中特征的数量\n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 01\n",
    "            Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(128),\n",
    "            ReLU(),\n",
    "            Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(128),\n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 02\n",
    "            Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(256),\n",
    "            ReLU(),\n",
    "            Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(256),\n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            # 03\n",
    "            Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(512),\n",
    "            ReLU(),\n",
    "            Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(512),\n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            Flatten(),\n",
    "            Linear(512 * 4, 10)\n",
    "        )\n",
    "\n",
    "        # Input: 3×28×28\n",
    "        self.conv_00 = Sequential(\n",
    "            Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(64),  # num_features：一般输入参数为batch_size*num_features*height*width，即为其中特征的数量\n",
    "            ReLU()\n",
    "        )\n",
    "        self.max_pool_00 = MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Input: 14×14\n",
    "        self.conv_01_00 = Sequential(\n",
    "            Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(128),\n",
    "            ReLU()\n",
    "        )\n",
    "        self.conv_01_01 = Sequential(\n",
    "            Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(128),\n",
    "            ReLU()\n",
    "        )\n",
    "        self.max_pool_01 = MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Input: 7×7\n",
    "        self.conv_02_00 = Sequential(\n",
    "            Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(256),\n",
    "            ReLU()\n",
    "        )\n",
    "        self.conv_02_01 = Sequential(\n",
    "            Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(256),\n",
    "            ReLU()\n",
    "        )\n",
    "        self.max_pool_02 = MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        # Input: 4×4\n",
    "        self.conv_03_00 = Sequential(\n",
    "            Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(512),\n",
    "            ReLU()\n",
    "        )\n",
    "        self.conv_03_01 = Sequential(\n",
    "            Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            BatchNorm2d(512),\n",
    "            ReLU()\n",
    "        )\n",
    "        self.max_pool_03 = MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        self.Flatten = Flatten()\n",
    "        self.linear = Linear(512 * 9, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # batchsize = X.size(0)\n",
    "\n",
    "        # _ = self.conv_00(X)\n",
    "        # _ = self.max_pool_00(_)\n",
    "        #\n",
    "        # _ = self.conv_01_00(_)\n",
    "        # _ = self.conv_01_01(_)\n",
    "        # _ = self.max_pool_01(_)\n",
    "        #\n",
    "        # _ = self.conv_02_00(_)\n",
    "        # _ = self.conv_02_01(_)\n",
    "        # _ = self.max_pool_02(_)\n",
    "        #\n",
    "        # _ = self.conv_03_00(_)\n",
    "        # _ = self.conv_03_01(_)\n",
    "        # _ = self.max_pool_03(_)\n",
    "        # print(_.shape)\n",
    "        # _ = self.Flatten(_)\n",
    "        # print(_.shape)\n",
    "        # _ = self.linear(_)\n",
    "        outputs = self.model(X)\n",
    "        # outputs = _\n",
    "        # outputs = functional.log_softmax(outputs)\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:35:09.896485Z",
     "start_time": "2023-06-28T04:35:09.853356600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6, 10])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGGNet()\n",
    "\n",
    "# 验证模型流程是否正确\n",
    "demo_input = torch.ones(6, 3, 28, 28)  # batch_size=6, in_channels=3, height=28, weight=28.\n",
    "model(demo_input).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:35:09.978069400Z",
     "start_time": "2023-06-28T04:35:09.862902900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n┃\u001B[1;35m \u001B[0m\u001B[1;35m    Date    \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35m              Title              \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mProduction Budget\u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35m  Box Office  \u001B[0m\u001B[1;35m \u001B[0m┃\n┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n│\u001B[2m \u001B[0m\u001B[2mDec 20, 2019\u001B[0m\u001B[2m \u001B[0m│ Star Wars: The Rise of Skywalker  │   $275,000,000    │  $375,126,118  │\n│\u001B[2m \u001B[0m\u001B[2mMay 25, 2018\u001B[0m\u001B[2m \u001B[0m│      \u001B[31mSolo\u001B[0m: A Star Wars Story      │   $275,000,000    │  $393,151,347  │\n│\u001B[2m \u001B[0m\u001B[2mDec 15, 2017\u001B[0m\u001B[2m \u001B[0m│ Star Wars Ep. VIII: The Last Jedi │   $262,000,000    │ \u001B[1m$1,332,539,889\u001B[0m │\n└──────────────┴───────────────────────────────────┴───────────────────┴────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">     Date     </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">               Title               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Production Budget </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   Box Office   </span>┃\n┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Dec 20, 2019 </span>│ Star Wars: The Rise of Skywalker  │   $275,000,000    │  $375,126,118  │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> May 25, 2018 </span>│      <span style=\"color: #800000; text-decoration-color: #800000\">Solo</span>: A Star Wars Story      │   $275,000,000    │  $393,151,347  │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Dec 15, 2017 </span>│ Star Wars Ep. VIII: The Last Jedi │   $262,000,000    │ <span style=\"font-weight: bold\">$1,332,539,889</span> │\n└──────────────┴───────────────────────────────────┴───────────────────┴────────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Column, Table\n",
    "\n",
    "console = Console()\n",
    "\n",
    "table = Table(show_header=True, header_style=\"bold magenta\")\n",
    "table.add_column(\"Date\", style=\"dim\", justify='center')\n",
    "table.add_column(\"Title\", justify='center')\n",
    "table.add_column(\"Production Budget\", justify='center')\n",
    "table.add_column(\"Box Office\", justify='center')\n",
    "table.add_row(\n",
    "    \"Dec 20, 2019\", \"Star Wars: The Rise of Skywalker\", \"$275,000,000\", \"$375,126,118\"\n",
    ")\n",
    "table.add_row(\n",
    "    \"May 25, 2018\",\n",
    "    \"[red]Solo[/red]: A Star Wars Story\",\n",
    "    \"$275,000,000\",\n",
    "    \"$393,151,347\",\n",
    ")\n",
    "table.add_row(\n",
    "    \"Dec 15, 2017\",\n",
    "    \"Star Wars Ep. VIII: The Last Jedi\",\n",
    "    \"$262,000,000\",\n",
    "    \"[bold]$1,332,539,889[/bold]\",\n",
    ")\n",
    "\n",
    "console.print(table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T04:37:54.849058700Z",
     "start_time": "2023-06-28T04:37:54.828693400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++ ==Ursula== +++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "print('+' * 25, \"Ursula\".center(10, '='), '+' * 25)  # 居中对齐"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T05:07:51.809167600Z",
     "start_time": "2023-06-28T05:07:51.782602300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for batch_num, (X, y) in enumerate(train_loader):\n",
    "    # X, y = X.to(device), y.to(device)\n",
    "    print(y)\n",
    "    # y_pred = model(X)\n",
    "    # loss = loss_fun(y_pred, y)\n",
    "    #\n",
    "    # # 反向传播\n",
    "    # optimizer.zero_grad()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    #\n",
    "    # print(f'Epoch is {epoch_num}, batch is {batch_num}, loss is: {loss.item()}.')\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-27T14:49:09.641955200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Finding device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Loss function\n",
    "loss_fun = CrossEntropyLoss()\n",
    "loss_fun.to(device)\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=learning_rate,\n",
    "#     momentum=.9,\n",
    "#     weight_decay=5e-4\n",
    "# )\n",
    "# 学习率的衰减, 每经过5轮更新梯度，学习率衰减为原来的0.9\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=.9)\n",
    "\n",
    "# Using tensorboard to visualize network structure\n",
    "writer = SummaryWriter('./logs')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T14:46:43.815768400Z",
     "start_time": "2023-06-27T14:46:43.642352900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "for epoch_num in range(epoch):\n",
    "\n",
    "    # model.train()\n",
    "    for batch_num, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        print(y)\n",
    "        # y_pred = model(X)\n",
    "        # loss = loss_fun(y_pred, y)\n",
    "        #\n",
    "        # # 反向传播\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        #\n",
    "        # print(f'Epoch is {epoch_num}, batch is {batch_num}, loss is: {loss.item()}.')\n",
    "        break\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-27T14:46:43.814745400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-27T15:10:17.964542Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
